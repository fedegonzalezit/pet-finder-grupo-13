{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as py\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score,balanced_accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from plotly import express as px\n",
    "from plotnine import ggplot, aes, geom_jitter, scale_colour_brewer, theme_minimal, labs, theme\n",
    "\n",
    "from utils.utils import plot_confusion_matrix\n",
    "\n",
    "import os\n",
    "\n",
    "import optuna\n",
    "from optuna.artifacts import FileSystemArtifactStore, upload_artifact\n",
    "\n",
    "from joblib import load, dump\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 30)\n",
    "plt.rcParams['figure.figsize'] = [12.0, 8.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_DIR = './'\n",
    "PETFINDER_PATH = \"../petfinder-adoption-prediction/\"\n",
    "PATH_TO_TRAIN = os.path.join(BASE_DIR, \"train/df_checkpoint_2.csv\") # este dataframe es train.csv + las features de las descripciones de DescriptionFeaturesPipeline.ipynb\n",
    "PATH_TO_MODELS = os.path.join(BASE_DIR, \"work/models\")\n",
    "PATH_TO_TEMP_FILES = os.path.join(BASE_DIR, \"work/optuna_temp_artifacts\")\n",
    "PATH_TO_OPTUNA_ARTIFACTS = os.path.join(BASE_DIR, \"work/optuna_artifacts\")\n",
    "\n",
    "PATH_TO_COLORS = os.path.join(PETFINDER_PATH, \"ColorLabels.csv\")\n",
    "PATH_TO_BREEDS = os.path.join(PETFINDER_PATH, \"BreedLabels.csv\")\n",
    "PATH_TO_STATES = os.path.join(PETFINDER_PATH, \"StateLabels.csv\")\n",
    "PATH_TO_TEST = os.path.join(BASE_DIR, \"test/test_df_checkpoint_2.csv\") # este dataframe es test.csv + las features de las descripciones de DescriptionFeaturesPipeline.ipynb\n",
    "\n",
    "PATH_TO_SENTIMENT_TRAIN = os.path.join(PETFINDER_PATH, \"train_sentiment/\")\n",
    "PATH_TO_SENTIMENT_TEST = os.path.join(PETFINDER_PATH, \"test_sentiment/\")\n",
    "\n",
    "PATH_PET_IMAGE_QUALITY_TRAIN = os.path.join(BASE_DIR, \"train/pet_images_quality.csv\")\n",
    "PATH_PET_IMAGE_QUALITY_TEST = os.path.join(\"./\", \"test/pet_images_quality_test.csv\")\n",
    "\n",
    "CLIP_FEATURES_TRAIN = os.path.join(BASE_DIR, \"train/clip_features.json\")\n",
    "CLIP_FEATURES_TEST = os.path.join(BASE_DIR, \"test/clip_features_test.json\")\n",
    "\n",
    "PATH_TO_METADATA_TRAIN = os.path.join(PETFINDER_PATH, \"train_metadata/\")\n",
    "PATH_TO_METADATA_TEST = os.path.join(PETFINDER_PATH, \"test_metadata/\")\n",
    "\n",
    "SEED = 42\n",
    "BATCH_SIZE = 50\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Datos Tabulares\n",
    "dataset = pd.read_csv(PATH_TO_TRAIN)\n",
    "test_dataset = pd.read_csv(PATH_TO_TEST)\n",
    "\n",
    "colors = pd.read_csv(PATH_TO_COLORS)\n",
    "breeds = pd.read_csv(PATH_TO_BREEDS)\n",
    "states = pd.read_csv(PATH_TO_STATES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape, test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['AdoptionSpeed'].value_counts().sort_index(ascending = False).plot(kind='barh', color='teal');\n",
    "plt.title('Adoption speed classes counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos adoption speed en proporciones: \n",
    "plt.figure(figsize=(14, 6))\n",
    "g = sns.countplot(x='AdoptionSpeed', data=dataset)\n",
    "plt.title('Adoption speed classes rates')\n",
    "ax=g.axes\n",
    "for p in ax.patches:\n",
    "     ax.annotate(f\"{p.get_height() * 100 / dataset.shape[0]:.2f}%\", (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "         ha='center', va='center', fontsize=11, color='gray', rotation=0, xytext=(0, 10),\n",
    "         textcoords='offset points')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que: \n",
    "\n",
    "-Algunas mascotas son adoptadas inmediatamente, pero es un pequeño porcentaje. (2%)\n",
    "\n",
    "-En general las mascotas tienen que esperar para ser adoptadas; Hay un 28% que debe esperar por lo menos 4 meses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRAFICO PERROS Y GATOS:\n",
    "dataset['Type'].value_counts().plot(kind='bar', color='teal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULO TASAS DE ADOPTION: ESTAS SON LAS TASAS DE ADOPCION GENERALES POR VELOCIDAD DE ADOPTION SIN DISTINCION ALGUNA. \n",
    "main_count = dataset['AdoptionSpeed'].value_counts(normalize=True).sort_index()\n",
    "print(main_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_maincount = dict(main_count)\n",
    "print(diccionario_maincount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCION QUE CALCULA TASA DE ADOPTION ESPECIFICA VS TASA DE ADOPTION GENERAL.  %Adoptado gato clase 0 / %clase 0\n",
    "def prepare_plot_dict(df, col, diccionario_maincount):\n",
    "    \n",
    "    plot_dict = {}\n",
    "    for i in df[col].unique():\n",
    "        val_count = dict(df.loc[df[col] == i, 'AdoptionSpeed'].value_counts().sort_index())\n",
    "\n",
    "        for k, v in diccionario_maincount.items():\n",
    "            if k in val_count:\n",
    "                plot_dict[val_count[k]] = ((val_count[k] / sum(val_count.values())) / diccionario_maincount[k]) * 100 - 100\n",
    "            else:\n",
    "                plot_dict[0] = 0\n",
    "\n",
    "    return plot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCION QUE GRAFICA EL COUNT PLOT DE ADOPTION SPEED CON LOS PORCENTAJES DE DIFERENCIA DE ADOPTION SPEED VS ADOPTION SPEED GENERAL.\n",
    "def make_count_plot(df, x, hue='AdoptionSpeed', title='', main_count=main_count):\n",
    "    g = sns.countplot(x=x, data=df, hue=hue)\n",
    "    plt.title(f'AdoptionSpeed {title}')\n",
    "    ax = g.axes\n",
    "\n",
    "    plot_dict = prepare_plot_dict(df, x, main_count)\n",
    "\n",
    "    for p in ax.patches:\n",
    "        h = p.get_height() if str(p.get_height()) != 'nan' else 0\n",
    "        if h == 0:\n",
    "            continue\n",
    "        text = f\"{plot_dict[h]:.0f}%\" if plot_dict[h] < 0 else f\"+{plot_dict[h]:.0f}%\"\n",
    "        ax.annotate(text, (p.get_x() + p.get_width() / 2., h),\n",
    "             ha='center', va='center', fontsize=11, color='green' if plot_dict[h] > 0 else 'red', rotation=0, xytext=(0, 10),\n",
    "             textcoords='offset points') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZACION ADOPTION SPEED POR TYPE: \n",
    "#POR QUE DA ERROR PERO SI MUESTRA EL GRAFICO Y RESULTADOS? \n",
    "prepare_plot_dict(dataset, 'Type', diccionario_maincount)\n",
    "make_count_plot(dataset, x='Type', title='by Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este grafico podemos observar que: \n",
    "\n",
    "-Gatos tienden a ser mas adoptados que los perros en las velocidades de adopcion mas rapidas. (Bajo adoptionspeed)\n",
    "\n",
    "-Los perros tienden a ser mas adoptados que los gatos luego de haber pasado mucho tiempo de espera en adopcion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANALISIS STATE: \n",
    "\n",
    "states_dict = {k: v for k, v in zip(states['StateID'], states['StateName'])}\n",
    "dataset['state_name'] = dataset['State'].apply(lambda x: '_'.join(states_dict[x].split()) if x in states_dict else 'Unknown')\n",
    "\n",
    "orden_state = dataset['state_name'].value_counts().index #Frecuencia de las combinaciones de colores ordenados de forma descendente. \n",
    "\n",
    "sns.countplot(data=dataset, x='state_name', order=orden_state)\n",
    "plt.title('state_name')\n",
    "plt.xticks(rotation=45)  # Rota las etiquetas del eje x si es necesario\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayoria de las publicaciones estan en Selangor & Kuala_Lumpur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for a in range(5):\n",
    "    df = dataset.loc[dataset['AdoptionSpeed'] == a]\n",
    "\n",
    "    data.append(go.Scatter(\n",
    "        x = df['Age'].value_counts().sort_index().index,\n",
    "        y = df['Age'].value_counts().sort_index().values,\n",
    "        name = str(a)\n",
    "    ))\n",
    "    \n",
    "layout = go.Layout(dict(title = \"AdoptionSpeed trends by Age\",\n",
    "                  xaxis = dict(title = 'Age (months)'),\n",
    "                  yaxis = dict(title = 'Counts'),\n",
    "                  )\n",
    "                  )\n",
    "py.iplot(dict(data=data, layout=layout), filename='basic-line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Las mas jovenes son las que mas rapido se adoptan.\n",
    "\n",
    "-Los picos en las edades siguen un patron: 2, 12, 24, 36, 48, 60 (puede ser porque se suele redondear a la hora de determinar la edad de la mascota)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANALISIS GENERO: \n",
    "#1 = Male, 2 = Female, 3 = Mixed, if profile represents group of pets\n",
    "make_count_plot(dataset, x='Gender', title= \"by Gender\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las tasas de adopcion son mas grandes para machos que para hembras; En el caso de no tener informacion disponible (gender=3) se puede ver una clara caida en la adopcion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANALISIS SALUD\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.subplot(2, 2, 1)\n",
    "make_count_plot(df=dataset, x='Vaccinated', title='Vaccinated')\n",
    "plt.xticks([0, 1, 2], ['Yes', 'No', 'Not sure'])\n",
    "plt.title('AdoptionSpeed and Vaccinated')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "make_count_plot(df=dataset, x='Dewormed', title='Dewormed')\n",
    "plt.xticks([0, 1, 2], ['Yes', 'No', 'Not sure'])\n",
    "plt.title('AdoptionSpeed and Dewormed')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "make_count_plot(df=dataset, x='Sterilized', title='Sterilized')\n",
    "plt.xticks([0, 1, 2], ['Yes', 'No', 'Not sure'])\n",
    "plt.title('AdoptionSpeed and Sterilized')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "make_count_plot(df=dataset, x='Health', title='Health')\n",
    "plt.xticks([0, 1, 2], ['Healthy', 'Minor Injury', 'Serious Injury'])\n",
    "plt.title('AdoptionSpeed and Health')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En todas las causisticas de SALUD, se puede ver que el hecho de NO tener informacion disponible reduce mucho las chances de ser adoptado. Podria ser interesante una nueva feature en base a esta informacion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pre Procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANALISIS NAME: \n",
    "\n",
    "# Contar NaN o Nulls en la columna 'Name'\n",
    "nan_null_count = dataset['Name'].isna().sum()\n",
    "\n",
    "# Contar registros vacíos en la columna 'Name'\n",
    "empty_string_count = (dataset['Name'] == '').sum()\n",
    "\n",
    "# Sumar ambos conteos para obtener el total de registros Nan/Nulls/Vacíos\n",
    "total_nan_null_empty = nan_null_count + empty_string_count\n",
    "\n",
    "print(f\"Total NaN/Nulls: {nan_null_count}\")\n",
    "print(f\"Total registros vacíos: {empty_string_count}\")\n",
    "print(f\"Total NaN/Nulls/Vacíos: {total_nan_null_empty}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reemplazo Na por Unnamed:\n",
    "dataset['Name'] = dataset['Name'].fillna('Unnamed')\n",
    "dataset['Name'] = dataset['Name'].replace('No Name Yet', 'Unnamed') \n",
    "dataset['Has_name'] = 1 #CREO UNA NUEVA COLUMNA QUE TENGA HAS_NAME = 1 ES DECIR, TODOS TIENEN NOMBRE\n",
    "dataset.loc[dataset['Name'] == 'Unnamed', 'Has_name'] = 0 #LUEGO CAMBJO HAS_NAME A 0 PARA LOS QUE NO TIENEN NOMBRE. (LOC ENTRO A FILAS DONDE NAME = UNNAME, COLUMNA HAS NAME)\n",
    "dataset.head()\n",
    "\n",
    "test_dataset['Name'] = test_dataset['Name'].fillna('Unnamed')\n",
    "test_dataset['Name'] = test_dataset['Name'].replace('No Name Yet', 'Unnamed')\n",
    "test_dataset['Has_name'] = 1\n",
    "test_dataset.loc[test_dataset['Name'] == 'Unnamed', 'Has_name'] = 0\n",
    "\n",
    "sns.countplot(x='Has_name', data=dataset, hue='AdoptionSpeed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROPORCION DE MASCOTAS SIN NOMBRE. \n",
    "print(f\"Rate of unnamed pets in train data: {(dataset['Has_name'] == 0).sum() * 100 / dataset.shape[0]:.4f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZAMOS LA ADOPTION SPEED RATE POR EL HECHO DE TENER O NO NOMBRE: \n",
    "make_count_plot(dataset, x='Has_name', title='by Has_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXISTEN \"MALOS NOMBRES\" O NOMBRES SIN SENTIDO? \n",
    "#CHECK NOMBRES CON MENOS DE 3 CARACTERES:\n",
    "dataset[dataset['Name'].apply(lambda x: len(str(x))) < 3]['Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos de la hipotesis de que el RescuerID puede ser un factor importante ya que algunos rescatistas podrian ser mas proactivos que otros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos si en el dataset de test hay rescatistas de train o son todos nuevos\n",
    "train_rescuers = dataset['RescuerID'].unique()\n",
    "test_rescuers = test_dataset['RescuerID'].unique()\n",
    "print(f\"Rescatistas en test que no estan en train: {len(set(test_rescuers) - set(train_rescuers))}\")\n",
    "print(f\"Rescatistas que estan en train y en test: {len(set(test_rescuers) & set(train_rescuers))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No usamos RescuerID porque no hay ningun Rescatista de train que se repita en test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset preprocesado en DescriptionFeaturesPipeline, tiene una nueva columna Language que es el lenguaje de la description, se transforma a categorica para que pueda ser procesada por LGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Language\"] = pd.Categorical(dataset[\"Language\"])\n",
    "test_dataset[\"Language\"] = pd.Categorical(test_dataset[\"Language\"], categories=dataset[\"Language\"].cat.categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engeneering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos features manuales derivadas de las features originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_name_feature(df):\n",
    "    \"\"\"\n",
    "    Como hay nombres que son un código, creamos una feature que indique eso\n",
    "    \"\"\"\n",
    "    df[\"bad_name\"] = 0\n",
    "    df.loc[df['Name'].apply(lambda x: len(str(x)) < 3), 'bad_name'] = 1\n",
    "    return df\n",
    "\n",
    "\n",
    "def desc_length_feature(df):\n",
    "    \"\"\"\n",
    "    Creamos una feature que indique la longitud de la descripción\n",
    "    \"\"\"\n",
    "    df['Description'] = df['Description'].fillna('')\n",
    "    df['desc_length'] = df['Description'].apply(lambda x: len(x))\n",
    "    return df\n",
    "\n",
    "def desc_words_feature(df):\n",
    "    \"\"\"\n",
    "    Creamos una feature que indique la cantidad de palabras en la descripción\n",
    "    \"\"\"\n",
    "    df['desc_words'] = df['Description'].apply(lambda x: len(x.split()))\n",
    "    return df\n",
    "\n",
    "def Pure_breed_feature(df):\n",
    "    \"\"\"\n",
    "    Creamos una feature que indique si la mascota es de raza pura\n",
    "    \"\"\"\n",
    "    df['Pure_breed'] = 0\n",
    "    df.loc[df['Breed2'] == 0, 'Pure_breed'] = 1\n",
    "    return df\n",
    "\n",
    "def num_colores_feature(df):\n",
    "    \"\"\"\n",
    "    Creamos una feature que indique la cantidad de colores de la mascota\n",
    "    \"\"\"\n",
    "    df['num_colores'] = df[['Color1', 'Color2', 'Color3']].apply(lambda x: sum(x != 0), axis=1)\n",
    "    return df\n",
    "\n",
    "def Free_feature(df):\n",
    "    \"\"\"\n",
    "    Creamos una feature que indique si la mascota es gratuita\n",
    "    \"\"\"\n",
    "    df['Free'] = df['Fee'].apply(lambda x: 1 if x == 0 else 0)\n",
    "    return df\n",
    "\n",
    "def health_combo_feature(df, df_train=None):\n",
    "    \"\"\"\n",
    "    Creamos una feature que indique la combinación de salud de la mascota\n",
    "    \"\"\"\n",
    "    df['health_combo'] = df.apply(lambda x: str(x['Vaccinated']) + str(x['Dewormed']) + str(x['Sterilized']) + str(x['Health']), axis=1)\n",
    "    \n",
    "    if df_train is not None:\n",
    "        df[\"health_combo\"] = pd.Categorical(df[\"health_combo\"], categories=df_train[\"health_combo\"].cat.categories)\n",
    "    else:\n",
    "        df[\"health_combo\"] = pd.Categorical(df[\"health_combo\"])\n",
    "    return df\n",
    "\n",
    "def color_combo_feature(df, df_train=None):\n",
    "    \"\"\"\n",
    "    Creamos una feature que indique la combinación de colores de la mascota\n",
    "    \"\"\"\n",
    "    df['color_combo'] = df.apply(lambda x: str(x['Color1']) + str(x['Color2']) + str(x['Color3']), axis=1)\n",
    "    if df_train is not None:\n",
    "        df[\"color_combo\"] = pd.Categorical(df[\"color_combo\"], categories=df_train[\"color_combo\"].cat.categories)\n",
    "    else:\n",
    "        df[\"color_combo\"] = pd.Categorical(df[\"color_combo\"])\n",
    "    return df\n",
    "\n",
    "def color_type_feature(df):\n",
    "    \"\"\"\n",
    "    Creamos una feature que indique si la mascota es de color puro o mezcla\n",
    "    1 = color puro\n",
    "    0 = mezcla\n",
    "    \"\"\"\n",
    "    df['color_type'] = df[['Color1', 'Color2', 'Color3']].apply(lambda x: 1 if sum(x != 0) == 1 else 0, axis=1)\n",
    "    return df\n",
    "\n",
    "def quantity_bucket_feature(df):\n",
    "    \"\"\"\n",
    "    Creamos una feature que indique el bucket de cantidad de mascotas\n",
    "    \"\"\"\n",
    "    def clasificar_quantity(quantity):\n",
    "        if quantity == 1:\n",
    "            return 1\n",
    "        elif 1 < quantity <= 3:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "    df['quantity_bucket'] = df['Quantity'].apply(clasificar_quantity)\n",
    "    return df\n",
    "\n",
    "def main_states_feature(df):\n",
    "    \"\"\"\n",
    "    Creamos una feature que indique si la mascota se encuentra en los estados principales\n",
    "    (Selangor & Kuala_Lumpur)\n",
    "    \"\"\"\n",
    "    df['main_states'] = df['State'].apply(lambda x: 1 if x in (41326,41401) else 0)\n",
    "    return df\n",
    "\n",
    "def has_video_feature(df):\n",
    "    \"\"\"\n",
    "    Creamos una feature que indique si la mascota tiene video\n",
    "    \"\"\"\n",
    "    df['has_video'] = df['VideoAmt'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    return df\n",
    "\n",
    "def photos_bucket_feature(df):\n",
    "    \"\"\"\n",
    "    Nueva variable que diferencie publicaciones por bucket de fotos\n",
    "    \"\"\"\n",
    "    def clasificar_quantity_fotos(PhotoAmt):\n",
    "        if PhotoAmt == 1:\n",
    "            return 1\n",
    "        elif 1 < PhotoAmt <= 5:\n",
    "            return 2\n",
    "        elif 5 < PhotoAmt <= 10:\n",
    "            return 3    \n",
    "        else:\n",
    "            return 4\n",
    "    df['photos_bucket'] = df['PhotoAmt'].apply(clasificar_quantity_fotos)\n",
    "    return df\n",
    "\n",
    "def fee_bucket_feature(df):\n",
    "    df['fee_bucket'] = df['Fee'].apply(lambda x: 1 if x == 0 else 2 if x <= 100 else 3)\n",
    "    return df\n",
    "\n",
    "def age_group_feature(df):\n",
    "    \"\"\"\n",
    "    Creamos una feature que indique el grupo de edad de la mascota\n",
    "    \"\"\"\n",
    "    def classify_age(age):\n",
    "        if age < 12:\n",
    "            return 1 #joven\n",
    "        elif 12 <= age <= 36:\n",
    "            return  2 #mediana edad\n",
    "        else:\n",
    "            return 3 #adulto\n",
    "\n",
    "    df['age_group']=df['Age'].apply(classify_age)\n",
    "    return df\n",
    "\n",
    "\n",
    "manual_features = [\n",
    "    \"bad_name\", \n",
    "    \"desc_length\", \n",
    "    \"desc_words\", \n",
    "    \"Pure_breed\", \n",
    "    \"num_colores\", \n",
    "    \"Free\",\n",
    "    \"health_combo\", \n",
    "    \"color_combo\", \n",
    "    \"color_type\", \n",
    "    \"quantity_bucket\", \n",
    "    \"main_states\", \n",
    "    \"has_video\", \n",
    "    \"photos_bucket\", \n",
    "    \"fee_bucket\",\n",
    "    \"age_group\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculo todas las features en el dataset de test y entrenamiento\n",
    "for feature in manual_features:\n",
    "    feature_func = globals()[feature + \"_feature\"]\n",
    "    dataset = feature_func(dataset)\n",
    "    if 'df_train' in feature_func.__code__.co_varnames:\n",
    "        test_dataset = feature_func(test_dataset, dataset)\n",
    "    else:\n",
    "        test_dataset = globals()[feature + \"_feature\"](test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisis de las features manuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANALISIS DESCRIPCION: \n",
    "dataset['desc_length'].plot(kind='hist', bins=20, color='teal') \n",
    "plt.title('Distribution of description_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COUNT PLOT DE DESCRIPTION LENGTH POR ADOPTION SPEED: ARMAR BUCKETS O VER PROMEDIOS. \n",
    "plt.figure(figsize=(16, 6));\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.violinplot(x=\"AdoptionSpeed\", y=\"desc_length\", hue=\"Type\", data=dataset)\n",
    "plt.title('AdoptionSpeed by Type and description length')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.violinplot(x=\"AdoptionSpeed\", y=\"desc_words\", hue=\"Type\", data=dataset)\n",
    "plt.title('AdoptionSpeed by Type and count of words in description')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Animales con descripciones mas cortas son adoptados mas rapido. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZAMOS LA ADOPTION SPEED RATE & BAD NAME\n",
    "make_count_plot(dataset, x='bad_name', title='by bad_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar que hay pocos casos de mascotas con nombres extraños (-bad names-); En el caso de adoption speed 0, muestra un -32% en la tasa de adoption & -47% en la de adopcion mas tardia. \n",
    "Los nombres los deberiamos borrar del set de datos para entrenar ya que son unicos. Mejor dejar feature que indique si tiene o no nombre/bad name feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZO ADOPTION SPEED RATE POR GRUPO DE EDAD:\n",
    "make_count_plot(dataset, x='age_group', title='by age_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df_dogs = dataset[dataset['Type'] == 1]\n",
    "filter_df_cats = dataset[dataset['Type'] == 2]\n",
    "\n",
    "make_count_plot(filter_df_dogs, x='Pure_breed', title='by DOGs Pure_breed') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_count_plot(filter_df_cats, x='Pure_breed', title='by CATs Pure_breed') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los animales que no son de raza pura son adoptados mas rapido. Se acentua mas en el caso de los gatos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRAFICO FEE BUCKET & ADOPTION SPEED: \n",
    "make_count_plot(dataset, x='fee_bucket', title='by fee_bucket')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayoria de las mascotas no tienen un fee para ser adoptadas. \n",
    "Para diferenciar tomamos como punto de corte FEE = 100 USD. \n",
    "Vemos que: \n",
    "El grupo 2 (mayor a 0 & menos de 100 USD): Tienen menos chances de ser adoptados en cada clase de adoption speed\n",
    "El grupo 3 (mayor a 100 USD) Tiene mejores chances vs el grupo 2. Quiza el FEE este asociado a otras caracteristicas: Salud del animal, adiestramiento, raza, ciudad. Pareceria haber un diferencial vs el grupo 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features utilizando el analisis de sentimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos el los json del proyecto con el analisis de sentimiento de las descripciones para crear nuevas features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_sentiment_features(df, path):\n",
    "    \"\"\"\n",
    "    Inserta las features de sentimientos en el dataframe\n",
    "    \"\"\"\n",
    "    sentiment_files = os.listdir(path)\n",
    "    scores = {}\n",
    "    for file in sentiment_files:\n",
    "        file_path = os.path.join(path, file)\n",
    "        if not file.endswith('.json'):\n",
    "            continue\n",
    "        with open(file_path, 'r') as f:\n",
    "            sentiment = json.load(f)\n",
    "            pet_id = file.split('.')[0]\n",
    "            scores[pet_id] = {\n",
    "                \"sentiment_score\": sentiment['documentSentiment']['score'],\n",
    "                \"sentiment_magnitude\": sentiment['documentSentiment']['magnitude']\n",
    "            }\n",
    "    sentiment_df = pd.DataFrame.from_dict(scores, orient='index')\n",
    "    sentiment_df.reset_index(inplace=True)\n",
    "    sentiment_df.columns = ['PetID', 'sentiment_score', 'sentiment_magnitude']\n",
    "    # merge sentiment features\n",
    "    df = pd.merge(df, sentiment_df, on='PetID', how='left')\n",
    "    return df\n",
    "\n",
    "def sentimiento(df):\n",
    "    def clasificar_sentimiento(sentiment_score):\n",
    "        if sentiment_score > 0.5:\n",
    "            return 1\n",
    "        elif sentiment_score < -0.5:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    df['sentiment'] = df['sentiment_score'].apply(clasificar_sentimiento)\n",
    "    return df\n",
    "\n",
    "sentiment_features =[\"sentiment_score\", \"sentiment_magnitude\", \"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = insert_sentiment_features(dataset, PATH_TO_SENTIMENT_TRAIN)\n",
    "test_dataset = insert_sentiment_features(test_dataset, PATH_TO_SENTIMENT_TEST)\n",
    "dataset = sentimiento(dataset)\n",
    "test_dataset = sentimiento(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(dataset, aes(x='AdoptionSpeed', y='sentiment_score', colour='factor(AdoptionSpeed)')) +\n",
    "geom_jitter(alpha=0.5) +\n",
    "scale_colour_brewer(palette=\"Dark2\", type=\"qual\") +\n",
    "theme_minimal() +\n",
    "labs(x=\"Adoption Speed\", y=\"sentiment_score\") +\n",
    "theme(legend_position=\"none\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(dataset, x='Breed1', y='sentiment_magnitude', color='AdoptionSpeed',\n",
    "                 labels={'Breed1': 'Breed', 'sentiment_magnitude': 'sentiment_magnitude'},\n",
    "                 title='Sentiment Magnitude by Breed1 for Different Adoption Speeds')\n",
    "\n",
    "# Update layout to add selection capability\n",
    "fig.update_layout(legend_title_text='Adoption Speed')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Jupyter ImageFeature.ipynb utiliza un zero-shot-clasificator para crear dos nuevas features en base a la imagen \"HighQualityImage\" y \"WellFocusedImage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_images_quality = pd.read_csv(PATH_PET_IMAGE_QUALITY_TRAIN)\n",
    "dataset = dataset.merge(pet_images_quality, on='PetID', how='left')\n",
    "\n",
    "pet_images_quality_test = pd.read_csv(PATH_PET_IMAGE_QUALITY_TEST)\n",
    "test_dataset = test_dataset.merge(pet_images_quality_test, on='PetID', how='left')\n",
    "\n",
    "features_images = [\"HighQualityImage\", \"WellFocusedImage\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Jupyter ImagesFeaturesClip.ipynb utiliza un modelo que genera features en base a una imagen. Para esto se utilizo la primer imagen de cada mascota. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clip_features_mean = [\"clip_mean_\"+str(i) for i in range(48)]\n",
    "def add_clips_features(df, path):\n",
    "    with open(path, \"r\") as f:\n",
    "        clip_features = json.load(f)\n",
    "    clip_features_df = pd.DataFrame(clip_features).T\n",
    "    clip_features_features_names = [f'clip_{i}' for i in range(clip_features_df.shape[1])]\n",
    "    clip_features_df.columns = clip_features_features_names\n",
    "    # el indice en realidad es una columna PetId\n",
    "    clip_features_df.reset_index(inplace=True)\n",
    "    clip_features_df.rename(columns={'index':'PetID'}, inplace=True)\n",
    "\n",
    "    # Como 768 features son muchas, reduzco la dimensionalidad a 48 calculando la media\n",
    "    for i in range(48):\n",
    "        clips_to_mean = [f'clip_{j}' for j in range(i*16, (i+1)*16)]\n",
    "        clip_features_df[clip_features_mean[i]] = clip_features_df[clips_to_mean].mean(axis=1)\n",
    "    # delete original features\n",
    "    clip_features_df.drop(clip_features_features_names, axis=1, inplace=True)\n",
    "    df = df.merge(clip_features_df, on='PetID', how='left')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>...</th>\n",
       "      <th>clip_mean_33</th>\n",
       "      <th>clip_mean_34</th>\n",
       "      <th>clip_mean_35</th>\n",
       "      <th>clip_mean_36</th>\n",
       "      <th>clip_mean_37</th>\n",
       "      <th>clip_mean_38</th>\n",
       "      <th>clip_mean_39</th>\n",
       "      <th>clip_mean_40</th>\n",
       "      <th>clip_mean_41</th>\n",
       "      <th>clip_mean_42</th>\n",
       "      <th>clip_mean_43</th>\n",
       "      <th>clip_mean_44</th>\n",
       "      <th>clip_mean_45</th>\n",
       "      <th>clip_mean_46</th>\n",
       "      <th>clip_mean_47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Nibble</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081039</td>\n",
       "      <td>-0.042430</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>-0.055048</td>\n",
       "      <td>-0.046137</td>\n",
       "      <td>-0.033951</td>\n",
       "      <td>-0.002770</td>\n",
       "      <td>-0.026052</td>\n",
       "      <td>-0.007847</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.014563</td>\n",
       "      <td>-0.023772</td>\n",
       "      <td>-0.020490</td>\n",
       "      <td>-0.051442</td>\n",
       "      <td>-0.059243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Unnamed</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102949</td>\n",
       "      <td>-0.051559</td>\n",
       "      <td>-0.029091</td>\n",
       "      <td>-0.125065</td>\n",
       "      <td>-0.010613</td>\n",
       "      <td>-0.026650</td>\n",
       "      <td>-0.047285</td>\n",
       "      <td>-0.003179</td>\n",
       "      <td>-0.026675</td>\n",
       "      <td>-0.013732</td>\n",
       "      <td>-0.004998</td>\n",
       "      <td>-0.022682</td>\n",
       "      <td>0.040870</td>\n",
       "      <td>-0.011127</td>\n",
       "      <td>0.011112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Brisco</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141652</td>\n",
       "      <td>-0.040403</td>\n",
       "      <td>-0.066333</td>\n",
       "      <td>0.015592</td>\n",
       "      <td>0.034930</td>\n",
       "      <td>-0.023217</td>\n",
       "      <td>-0.113306</td>\n",
       "      <td>-0.013069</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>-0.032645</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>-0.051696</td>\n",
       "      <td>-0.011268</td>\n",
       "      <td>-0.062509</td>\n",
       "      <td>0.022732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Miko</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.142874</td>\n",
       "      <td>-0.095632</td>\n",
       "      <td>-0.066506</td>\n",
       "      <td>-0.049919</td>\n",
       "      <td>0.019752</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>-0.050995</td>\n",
       "      <td>-0.021675</td>\n",
       "      <td>0.069602</td>\n",
       "      <td>-0.047197</td>\n",
       "      <td>0.032714</td>\n",
       "      <td>-0.025757</td>\n",
       "      <td>-0.011036</td>\n",
       "      <td>-0.073924</td>\n",
       "      <td>0.003733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128990</td>\n",
       "      <td>-0.051718</td>\n",
       "      <td>-0.076471</td>\n",
       "      <td>-0.000623</td>\n",
       "      <td>0.079659</td>\n",
       "      <td>-0.013315</td>\n",
       "      <td>-0.038462</td>\n",
       "      <td>-0.039584</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>-0.038545</td>\n",
       "      <td>-0.037867</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>0.013154</td>\n",
       "      <td>-0.027284</td>\n",
       "      <td>-0.024250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type     Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n",
       "0     2   Nibble    3     299       0       1       1       7       0   \n",
       "1     2  Unnamed    1     265       0       1       1       2       0   \n",
       "2     1   Brisco    1     307       0       1       2       7       0   \n",
       "3     1     Miko    4     307       0       2       1       2       0   \n",
       "4     1   Hunter    1     307       0       1       1       0       0   \n",
       "\n",
       "   MaturitySize  FurLength  Vaccinated  Dewormed  Sterilized  Health  ...  \\\n",
       "0             1          1           2         2           2       1  ...   \n",
       "1             2          2           3         3           3       1  ...   \n",
       "2             2          2           1         1           2       1  ...   \n",
       "3             2          1           1         1           2       1  ...   \n",
       "4             2          1           2         2           2       1  ...   \n",
       "\n",
       "   clip_mean_33  clip_mean_34  clip_mean_35 clip_mean_36  clip_mean_37  \\\n",
       "0     -0.081039     -0.042430      0.002275    -0.055048     -0.046137   \n",
       "1     -0.102949     -0.051559     -0.029091    -0.125065     -0.010613   \n",
       "2     -0.141652     -0.040403     -0.066333     0.015592      0.034930   \n",
       "3     -0.142874     -0.095632     -0.066506    -0.049919      0.019752   \n",
       "4     -0.128990     -0.051718     -0.076471    -0.000623      0.079659   \n",
       "\n",
       "  clip_mean_38 clip_mean_39  clip_mean_40  clip_mean_41 clip_mean_42  \\\n",
       "0    -0.033951    -0.002770     -0.026052     -0.007847     0.002889   \n",
       "1    -0.026650    -0.047285     -0.003179     -0.026675    -0.013732   \n",
       "2    -0.023217    -0.113306     -0.013069      0.016932    -0.032645   \n",
       "3     0.007646    -0.050995     -0.021675      0.069602    -0.047197   \n",
       "4    -0.013315    -0.038462     -0.039584      0.006617    -0.038545   \n",
       "\n",
       "  clip_mean_43  clip_mean_44  clip_mean_45  clip_mean_46  clip_mean_47  \n",
       "0     0.014563     -0.023772     -0.020490     -0.051442     -0.059243  \n",
       "1    -0.004998     -0.022682      0.040870     -0.011127      0.011112  \n",
       "2     0.000530     -0.051696     -0.011268     -0.062509      0.022732  \n",
       "3     0.032714     -0.025757     -0.011036     -0.073924      0.003733  \n",
       "4    -0.037867      0.009862      0.013154     -0.027284     -0.024250  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = add_clips_features(dataset, CLIP_FEATURES_TRAIN)\n",
    "test_dataset = add_clips_features(test_dataset, CLIP_FEATURES_TEST)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18497, 107)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos los metadatos del analisis de imagenes que está en el proyecto, para eso creamos 3 nuevas columnas color_red, color_blue y color_green que son los valores RGB del color principal de todas las imagenes para una mascota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_metadata(path):\n",
    "    metadata_jsons = {} # dict the petid y list of jsons\n",
    "\n",
    "    for metadata_file in os.listdir(path):\n",
    "        with open(os.path.join(path, metadata_file), 'r') as f:\n",
    "\n",
    "            image_name = metadata_file.split('.')[0]\n",
    "            pet_id = image_name.split('-')[0]\n",
    "            if pet_id not in metadata_jsons:\n",
    "                metadata_jsons[pet_id] = []\n",
    "            metadata_jsons[pet_id].append(json.load(f))\n",
    "    return metadata_jsons\n",
    "\n",
    "def obtain_main_color(metadata_jsons):\n",
    "    main_colors = {}\n",
    "\n",
    "    for pet_id, metadata in metadata_jsons.items():\n",
    "        max_score = 0\n",
    "        main_color = None\n",
    "        for m in metadata:\n",
    "            if 'imagePropertiesAnnotation' in m:\n",
    "                for color in m['imagePropertiesAnnotation']['dominantColors']['colors']:\n",
    "                    if color['score'] > max_score:\n",
    "                        max_score = color['score']\n",
    "                        main_color = [color['color']['red'], color['color']['green'], color['color']['blue']]\n",
    "        main_colors[pet_id] = main_color\n",
    "    return main_colors\n",
    "\n",
    "def add_metadata_features(df, main_colors):\n",
    "    main_colors_df = pd.DataFrame(main_colors).T\n",
    "    main_colors_df.columns = ['main_color_red', 'main_color_green', 'main_color_blue']\n",
    "    main_colors_df.reset_index(inplace=True)\n",
    "    main_colors_df.rename(columns={'index':'PetID'}, inplace=True)\n",
    "    df = pd.merge(df, main_colors_df, on='PetID', how='left')\n",
    "    return df\n",
    "\n",
    "metadata_features = [\"main_color_red\", \"main_color_green\", \"main_color_blue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_train = read_metadata(PATH_TO_METADATA_TRAIN)\n",
    "main_colors_train = obtain_main_color(metadata_train)\n",
    "dataset = add_metadata_features(dataset, main_colors_train)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_test = read_metadata(PATH_TO_METADATA_TEST)\n",
    "main_colors_test = obtain_main_color(metadata_test)\n",
    "test_dataset = add_metadata_features(test_dataset, main_colors_test)\n",
    "test_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los dataset preprocesados por DescriptionFeaturesPipeline utilizan un LLM para analizar las descripciones y crear las siguientes features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_features = [\n",
    "    'Is the pet described as friendly?',\n",
    "    'Does the pet require special care?',\n",
    "    'Is the pet currently with the owner?',\n",
    "    'Is the pet good with other animals?', \n",
    "    \"Is the pet's adoption urgent?\",\n",
    "    'Does the pet need a lot of space?',\n",
    "    'Is the pet described as lovely or loveable?',\n",
    "    'Is there a contact person mentioned?',\n",
    "    'Must these pets be adopted as a group?',\n",
    "    'Does the pet need medical care?', \n",
    "    'must always be kept indoors',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = [\n",
    "    \"Type\",\n",
    "    'Age',\n",
    "    'Breed1',\n",
    "    'Breed2',\n",
    "    'Gender',\n",
    "    'Color1',\n",
    "    'Color2',\n",
    "    'Color3',\n",
    "    'MaturitySize',\n",
    "    'FurLength',\n",
    "    'Vaccinated',\n",
    "    'Dewormed',\n",
    "    'Sterilized',\n",
    "    'Health',\n",
    "    'Quantity',\n",
    "    'Fee',\n",
    "    'State',\n",
    "    'VideoAmt',\n",
    "    'PhotoAmt',\n",
    "]\n",
    "features = (\n",
    "    original_features + \n",
    "    manual_features + \n",
    "    sentiment_features + \n",
    "    features_images + \n",
    "    llm_features + \n",
    "    metadata_features + \n",
    "    clip_features_mean\n",
    ")\n",
    "label = 'AdoptionSpeed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Separa la base de Test y Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset,\n",
    "                               test_size = TEST_SIZE,\n",
    "                               random_state = SEED,\n",
    "                               stratify = dataset.AdoptionSpeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[features]\n",
    "y_train = train[label]\n",
    "\n",
    "X_test = test[features]\n",
    "y_test = test[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = params = {\n",
    "                        'objective': 'multiclass',\n",
    "                        'num_class': len(y_train.unique())\n",
    "                        }\n",
    "\n",
    "\n",
    "lgb_train_dataset = lgb.Dataset(data=X_train,\n",
    "                                label=y_train,)\n",
    "\n",
    "\n",
    "lgb_model = lgb.train(lgb_params,\n",
    "                      lgb_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgb_model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "cohen_kappa_score(y_test,y_pred, weights = 'quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(lgb_model, importance_type='gain', figsize=(10,10), max_num_features=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Para la parte de Train, armar un esquema de Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_store = FileSystemArtifactStore(base_path=PATH_TO_OPTUNA_ARTIFACTS)\n",
    "\n",
    "def lgb_custom_metric_kappa(dy_pred, dy_true):\n",
    "\n",
    "    metric_name = 'kappa'\n",
    "    value = cohen_kappa_score(dy_true.get_label(),dy_pred.argmax(axis=1),weights = 'quadratic')\n",
    "    is_higher_better = True\n",
    "    return(metric_name, value, is_higher_better)\n",
    "\n",
    "def cv_es_lgb_objective(trial):\n",
    "\n",
    "    lgb_params = {      \n",
    "                        'objective': 'multiclass',\n",
    "                        'verbosity':-1,\n",
    "                        'num_class': len(y_train.unique()),\n",
    "                        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "                        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "                        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "                        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "                        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "                        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "                        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "                        } \n",
    "\n",
    "    scores_ensemble = np.zeros((len(y_test),len(y_train.unique())))\n",
    "    score_folds = 0\n",
    "    n_splits = 5\n",
    "\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "    for i, (if_index, oof_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        \n",
    "        lgb_if_dataset = lgb.Dataset(data=X_train.iloc[if_index],\n",
    "                                        label=y_train.iloc[if_index],\n",
    "                                        free_raw_data=False)\n",
    "        \n",
    "        lgb_oof_dataset = lgb.Dataset(data=X_train.iloc[oof_index],\n",
    "                                        label=y_train.iloc[oof_index],\n",
    "                                        free_raw_data=False)\n",
    "\n",
    "        lgb_model = lgb.train(lgb_params,\n",
    "                                lgb_if_dataset,\n",
    "                                valid_sets=lgb_oof_dataset,\n",
    "                                callbacks=[lgb.early_stopping(10, verbose=False)],\n",
    "                                feval = lgb_custom_metric_kappa\n",
    "                                )\n",
    "        \n",
    "        scores_ensemble = scores_ensemble + lgb_model.predict(X_test) #prediction!!!!\n",
    "        \n",
    "        score_folds = score_folds + cohen_kappa_score(y_train.iloc[oof_index], \n",
    "                                                            lgb_model.predict(X_train.iloc[oof_index]).argmax(axis=1),weights = 'quadratic')/n_splits\n",
    "\n",
    "\n",
    "    predicted_filename = os.path.join(PATH_TO_TEMP_FILES,f'test_{trial.study.study_name}_{trial.number}.joblib')\n",
    "    predicted_df = test.copy()\n",
    "    predicted_df['pred'] = [scores_ensemble[p,:] for p in range(scores_ensemble.shape[0])]\n",
    "    dump(predicted_df, predicted_filename)\n",
    "    upload_artifact(trial, predicted_filename, artifact_store)    \n",
    "\n",
    "    cm_filename = os.path.join(PATH_TO_TEMP_FILES,f'cm_{trial.study.study_name}_{trial.number}.jpg')\n",
    "    plot_confusion_matrix(y_test,scores_ensemble.argmax(axis=1)).write_image(cm_filename)\n",
    "    upload_artifact(trial, cm_filename, artifact_store)\n",
    "\n",
    "    test_score = cohen_kappa_score(y_test,scores_ensemble.argmax(axis=1),weights = 'quadratic')\n",
    "    trial.set_user_attr(\"test_score\", test_score)\n",
    "\n",
    "    return(score_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# usamos n_startup_trials de 28 porque optimizamos 7 variables (4*7)\n",
    "sampler = optuna.samplers.TPESampler(seed=SEED, n_startup_trials=28)\n",
    "\n",
    "study = optuna.create_study(direction='maximize',\n",
    "                            storage=\"sqlite:///db.sqlite3\",  # Specify the storage URL here.\n",
    "                            study_name=\"TP Final\",\n",
    "                            load_if_exists = True)\n",
    "\n",
    "study.optimize(cv_es_lgb_objective, n_trials=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reentrenamos el modelo con los mejores hiperparámetros y lo probamos en test\n",
    "best_params = study.best_params\n",
    "lgb_params = {\n",
    "    \"objetive\": \"multiclass\",\n",
    "    \"num_class\": len(y_train.unique()),\n",
    "    \"verbosity\": -1,\n",
    "    **best_params\n",
    "}\n",
    "\n",
    "lgb_train_dataset = lgb.Dataset(data=X_train,\n",
    "                                label=y_train)\n",
    "lgb_model = lgb.train(lgb_params,\n",
    "                        lgb_train_dataset)\n",
    "\n",
    "y_pred = lgb_model.predict(X_test).argmax(axis=1)\n",
    "cohen_kappa_score(y_test, y_pred, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(lgb_model, importance_type='gain', figsize=(10,10), max_num_features=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Prediccion para kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reentrenamos el modelo con los mejores parametros pero para todo el dataset\n",
    "lgb_train_dataset = lgb.Dataset(data=dataset[features],\n",
    "                                label=dataset[label])\n",
    "lgb_model = lgb.train(lgb_params,\n",
    "                        lgb_train_dataset)\n",
    "\n",
    "# guardamos el modelo\n",
    "model_filename = os.path.join(PATH_TO_MODELS, \"lgb_final_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predecimos sobre el dataset de test\n",
    "test_dataset['AdoptionSpeed'] = lgb_model.predict(test_dataset[features]).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos submit.csv y lo guardamos en este directorio\n",
    "submit_df = test_dataset[['PetID', 'AdoptionSpeed']]\n",
    "submit_df.to_csv(\"submit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Valoración del modelo/conclusiones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labo2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
